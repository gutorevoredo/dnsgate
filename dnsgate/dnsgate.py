#!/usr/bin/env python3
# tab-width:4
# pylint: disable=missing-docstring

# PUBLIC DOMAIN
# http://github.com/jkeogh/dnsgate
# "psl domain" is "Public Second Level Domain" extracted using https://publicsuffix.org/
__version__ = "0.0.1"

import click
import copy
import time
import glob
import hashlib
import sys
import os
import shutil
import requests
import tldextract
import pprint
import configparser
from shutil import copyfileobj
import logging

class logmaker():
    def __init__(self, output_format, name, level):
        self.logger = logging.getLogger(name)
        self.logger_ch = logging.StreamHandler()
        self.formatter = logging.Formatter(output_format)
        self.logger_ch.setFormatter(self.formatter)
        self.logger.addHandler(self.logger_ch)
        self.logger.setLevel(level)

LOG_LEVELS = {
    'CRITICAL':logging.CRITICAL,    # 50
    'ERROR':   logging.ERROR,       # 40
    'WARNING': logging.WARNING,     # 30    # python default level
    'INFO':    logging.INFO,        # 20
    'DEBUG':   logging.DEBUG        # 10
    }

FORMAT = "%(levelname)-5s %(lineno)4s %(filename)-18s:%(funcName)-13s : %(message)s"
QUIET_FORMAT = "%(message)s"
logger_quiet = logmaker(output_format=QUIET_FORMAT, name="logging_quiet", level=LOG_LEVELS['INFO'])

def set_verbose(ctx, param, verbose=False):
    if verbose:
        logger_quiet.logger.setLevel(LOG_LEVELS['INFO'])
    else:
        logger_quiet.logger.setLevel(LOG_LEVELS['INFO'] + 1)

CONFIG_DIRECTORY = '/etc/dnsgate'
CONFIG_FILE = CONFIG_DIRECTORY + '/config'
CACHE_DIRECTORY = CONFIG_DIRECTORY + '/cache'
TLDEXTRACT_CACHE = CACHE_DIRECTORY + '/tldextract_cache'
CUSTOM_BLACKLIST = CONFIG_DIRECTORY + '/blacklist'
CUSTOM_WHITELIST = CONFIG_DIRECTORY + '/whitelist'
DEFAULT_OUTPUT_FILE = CONFIG_DIRECTORY + '/generated_blacklist'
DNSMASQ_CONFIG_FILE = '/etc/dnsmasq.conf'
DEFAULT_REMOTE_BLACKLISTS = ['http://winhelp2002.mvps.org/hosts.txt', 'http://someonewhocares.org/hosts/hosts']
DEFAULT_CACHE_EXPIRE = 3600 * 24 * 2 # 48 hours
TLD_EXTRACT = tldextract.TLDExtract(cache_file=TLDEXTRACT_CACHE)

def eprint(*args, level, **kwargs):
    if level == LOG_LEVELS['INFO']:
        logger_quiet.logger.info(*args, **kwargs)
    elif level >= LOG_LEVELS['WARNING']:
        logger_quiet.logger.warning(*args, **kwargs)

def make_output_file_header(config_dict):
    configuration_string = '\n'.join(['#    ' + str(key) + ': ' +
        str(config_dict[key]) for key in config_dict.keys()])
    output_file_header = '#' * 64 + '''\n#
# AUTOMATICALLY GENERATED BY dnsgate:
#    https://github.com/jakeogh/dnsgate\n#
# CHANGES WILL BE LOST ON THE NEXT RUN.\n#
# EDIT ''' + CUSTOM_BLACKLIST + ' or ' + \
        CUSTOM_WHITELIST + ' instead.\n#\n' + \
        '# Generated by:\n# ' + ' '.join(sys.argv) + \
        '\n#' + '\n# Configuration:\n' + configuration_string + '\n#\n' + '#' * 64 + '\n\n'
    return output_file_header.encode('utf8')

class Dnsgate_Config():
    def __init__(self, mode=False, dnsmasq_config=None, backup=False,
        no_restart_dnsmasq=False, block_at_psl=False, dest_ip=None):
        self.mode = mode
        self.no_restart_dnsmasq = no_restart_dnsmasq
        self.backup = backup
        self.dnsmasq_config = dnsmasq_config
        self.block_at_psl = block_at_psl
        self.dest_ip = dest_ip

def restart_dnsmasq_service():
    if os.path.lexists('/etc/init.d/dnsmasq'):
        os.system('/etc/init.d/dnsmasq restart 1>&2')
    else:
        os.system('systemctl restart dnsmasq 1>&2')  # untested
    return True

def hash_str(string):
    assert isinstance(string, str)
    assert len(string) > 0
    return hashlib.sha1(string.encode('utf-8')).hexdigest()

def remove_comments_from_bytes(line):
    assert isinstance(line, bytes)
    uncommented_line = b''
    for char in line:
        char = bytes([char])
        if char != b'#':
            uncommented_line += char
        else:
            break
    return uncommented_line

def comment_out_line_in_file(fh, line_to_match):
    '''
    add a # to the beginning of all instances of line_to_match
    iff there is not already a # preceding line_to_match and
        line_to_match is the only thing on the line
            except possibly a preceeding # and/or whitespace

    if line_to_match is found and all instances are commented out return True
    if line_to_match is found and all instances are already commented out return True
    if line_to_match is not found return False
    '''
    with open(fh.name, 'r') as rfh:
        lines = rfh.read().splitlines()
    newlines = []
    commented = False
    for line in lines:
        if line_to_match in line:
            line_stripped = line.strip()
            if line_stripped.startswith('#'):
                newlines.append(line)
                commented = True
                continue
            else:
                if line_stripped == line:
                    newlines.append('#' + line)
                    commented = True
                    continue
                else:
                    newlines.append(line)
                    continue
        else:
            newlines.append(line)
    if lines != newlines:
        fh.write('\n'.join(newlines) + '\n')
        return True
    elif commented:
        return True
    return False

def uncomment_line_in_file(fh, line_to_match):
    '''
    remove # from the beginning of all instances of line_to_match
    iff there is already a # preceding line_to_match and
        line_to_match is the only thing on the line
            except possibly a preceeding # and/or whitespace

    if line_to_match is found and all instances are uncommented return True
    if line_to_match is found and all instances are already uncommented return True
    if line_to_match is not found return False
    '''
    with open(fh.name, 'r') as rfh:
        lines = rfh.read().splitlines()
    newlines = []
    uncommented = False
    for line in lines:
        if line_to_match in line:
            line_stripped = line.strip()
            if line_stripped.startswith('#'):
                newlines.append(line[1:])
                uncommented = True
                continue
            else:
                if line_stripped == line:
                    newlines.append(line)
                    uncommented = True
                    continue
                else:
                    newlines.append(line)
                    continue
        else:
            newlines.append(line)

    if lines != newlines:
        fh.write('\n'.join(newlines) + '\n')
        return True
    if uncommented:
        return True
    return False

def group_by_tld(domains):
    eprint('Sorting domains by their subdomain and grouping by TLD.',
        level=LOG_LEVELS['INFO'])
    sorted_output = []
    reversed_domains = []
    for domain in domains:
        rev_domain = domain.split(b'.')
        rev_domain.reverse()
        reversed_domains.append(rev_domain)
    reversed_domains.sort() # sorting a list of lists by the tld
    for rev_domain in reversed_domains:
        rev_domain.reverse()
        sorted_output.append(b'.'.join(rev_domain))
    return sorted_output

def extract_psl_domain(domain):
    dom = TLD_EXTRACT(domain.decode('utf-8'))
    dom = dom.domain + '.' + dom.suffix
    return dom.encode('utf-8')

def strip_to_psl(domains):
    '''This causes ad-serving domains to be blocked at their root domain.
    Otherwise the subdomain can be changed until the --url lists are updated.
    It does not make sense to use this flag if you are generating a /etc/hosts
    format file since the effect would be to block google.com and not
    *.google.com.'''
    eprint('Removing subdomains on %d domains.', len(domains),
        level=LOG_LEVELS['INFO'])
    domains_stripped = set()
    for line in domains:
        line = extract_psl_domain(line)
        domains_stripped.add(line)
    return domains_stripped

def write_unique_line(line, file_to_write):
    '''
    Write line to file_to_write iff line not in file_to_write.
    '''
    try:
        with open(file_to_write, 'r+') as fh:
            if line not in fh:
                fh.write(line)
    except FileNotFoundError:
        with open(file_to_write, 'a') as fh:
            fh.write(line)

def backup_file_if_exists(file_to_backup):
    timestamp = str(time.time())
    dest_file = file_to_backup.name + '.bak.' + timestamp
    try:
        with open(file_to_backup.name, 'r') as sf:
            with open(dest_file, 'x') as df:
                copyfileobj(sf, df)
    except FileNotFoundError:
        pass    # skip backup if file does not exist

def validate_domain_list(domains):
    eprint('Validating %d domains.', len(domains), level=LOG_LEVELS['DEBUG'])
    valid_domains = set([])
    for hostname in domains:
        try:
            hostname = hostname.decode('utf-8')
            hostname = hostname.encode('idna').decode('ascii')
            valid_domains.add(hostname.encode('utf-8'))
        except Exception as e:
            logger_quiet.logger.exception(e)
    return valid_domains

def generate_dnsmasq_config_line(output_file):
    dnsmasq_config_line = 'conf-file=' + output_file
    return dnsmasq_config_line

def dnsmasq_install_help(dnsmasq_config, output_file=DEFAULT_OUTPUT_FILE):
    dnsmasq_config_line = generate_dnsmasq_config_line(output_file)
    print('    $ cp -vi ' + dnsmasq_config + ' ' + dnsmasq_config + '.bak.' + str(time.time()), file=sys.stderr)
    print('    $ grep ' + dnsmasq_config_line + ' ' + dnsmasq_config + '|| { echo '
        + dnsmasq_config_line + ' >> dnsmasq_config ; }', file=sys.stderr)
    print('    $ /etc/init.d/dnsmasq restart', file=sys.stderr)

def hosts_install_help(output_file=DEFAULT_OUTPUT_FILE):
    print('    $ mv -vi /etc/hosts /etc/hosts.default', file=sys.stderr)
    print('    $ cat /etc/hosts.default ' + output_file + ' > /etc/hosts', file=sys.stderr)

def append_to_local_rule_file(rule_file, idn):
    eprint("attempting to append %s to %s", idn, rule_file, level=LOG_LEVELS['INFO'])
    hostname = idn.encode('idna').decode('ascii')
    eprint("appending hostname: %s to %s", hostname, rule_file, level=LOG_LEVELS['DEBUG'])
    line = hostname + '\n'
    write_unique_line(line, rule_file)

def extract_domain_set_from_dnsgate_format_file(dnsgate_file):
    domains = set([])
    dnsgate_file = os.path.abspath(dnsgate_file)
    try:
        dnsgate_file_bytes = read_file_bytes(dnsgate_file)
    except Exception as e:
        logger_quiet.logger.exception(e)
    else:
        lines = dnsgate_file_bytes.splitlines()
        for line in lines:
            line = line.strip()
            line = remove_comments_from_bytes(line)
            line = b'.'.join(list(filter(None, line.split(b'.')))) # ignore leading/trailing .
            if len(line) > 0:
                domains.add(line)
    return set(domains)

def read_file_bytes(file):
    if os.path.isfile(file):
        with open(file, 'rb') as fh:
            file_bytes = fh.read()
        return file_bytes
    else:
        raise FileNotFoundError(file + ' does not exist.')

def extract_domain_set_from_hosts_format_url_or_cached_copy(url, no_cache=False, cache_expire=DEFAULT_CACHE_EXPIRE):
    unexpired_copy = get_newest_unexpired_cached_url_copy(url=url, cache_expire=cache_expire)
    if unexpired_copy:
        eprint("Using cached copy: %s", unexpired_copy, level=LOG_LEVELS['INFO'])
        unexpired_copy_bytes = read_file_bytes(unexpired_copy)
        assert isinstance(unexpired_copy_bytes, bytes)
        return extract_domain_set_from_hosts_format_bytes(unexpired_copy_bytes)
    else:
        return extract_domain_set_from_hosts_format_url(url, no_cache)

def generate_cache_file_name(url):
    url_hash = hash_str(url)
    file_name = CACHE_DIRECTORY + '/' + url_hash + '_hosts'
    return file_name

def get_newest_unexpired_cached_url_copy(url, cache_expire=DEFAULT_CACHE_EXPIRE):
    newest_copy = get_matching_cached_file(url)
    if newest_copy:
        newest_copy_timestamp = os.stat(newest_copy).st_mtime
        expiration_timestamp = int(newest_copy_timestamp) + int(cache_expire)
        if expiration_timestamp > time.time():
            return newest_copy
        else:
            os.rename(newest_copy, newest_copy + '.expired')
            return False
    return False

def get_matching_cached_file(url):
    name = generate_cache_file_name(url)
    matching_cached_file = glob.glob(name)
    if matching_cached_file:
        return matching_cached_file[0]
    else:
        return False

def read_url_bytes(url, no_cache=False):
    eprint("GET: %s", url, level=LOG_LEVELS['DEBUG'])
    user_agent = 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0'
    try:
        raw_url_bytes = requests.get(url, headers={'User-Agent': user_agent}, allow_redirects=True,
            stream=False, timeout=15.500).content
    except Exception as e:
        logger_quiet.logger.exception(e)
        return False
    if not no_cache:
        cache_index_file = CACHE_DIRECTORY + '/sha1_index'
        cache_file = generate_cache_file_name(url)
        with open(cache_file, 'xb') as fh:
            fh.write(raw_url_bytes)

        line_to_write = cache_file + ' ' + url + '\n'
        write_unique_line(line_to_write, cache_index_file)

    eprint("Returning %d bytes from %s", len(raw_url_bytes), url, level=LOG_LEVELS['DEBUG'])
    return raw_url_bytes

def extract_domain_set_from_hosts_format_bytes(hosts_format_bytes):
    assert isinstance(hosts_format_bytes, bytes)
    domains = set()
    hosts_format_bytes_lines = hosts_format_bytes.split(b'\n')
    for line in hosts_format_bytes_lines:
        line = line.replace(b'\t', b' ')         # expand tabs
        line = b' '.join(line.split())           # collapse whitespace
        line = line.strip()
        line = remove_comments_from_bytes(line)
        if b' ' in line:                         # hosts format
            line = line.split(b' ')[1]           # get DNS name (the url's are in hosts 0.0.0.0 dom.com format)
            # pylint: disable=bad-builtin
            line = b'.'.join(list(filter(None, line.split(b'.'))))    # ignore leading/trailing .
            # pylint: enable=bad-builtin
            domains.add(line)
    return domains

def extract_domain_set_from_hosts_format_url(url, no_cache=False):
    url_bytes = read_url_bytes(url, no_cache)
    domains = extract_domain_set_from_hosts_format_bytes(url_bytes)
    eprint("Domains in %s:%s", url, len(domains), level=LOG_LEVELS['DEBUG'])
    return domains

def prune_redundant_rules(domains_combined):
    domains_combined_orig = copy.deepcopy(domains_combined) # need to iterate through _orig later
    for domain in domains_combined_orig:
        if b'.' in domain:
            domain_parts = domain.split(b'.')
            domain_parts.pop(0)
            parent_domain = b'.'.join(domain_parts)
            if parent_domain in domains_combined:
                eprint("removing: %s because it's parent domain: %s is already blocked", domain, parent_domain,
                    level=LOG_LEVELS['DEBUG'])
                domains_combined.remove(domain)
    return domains_combined

OUTPUT_FILE_HELP = 'output file (defaults to ' + DEFAULT_OUTPUT_FILE + ')'
DNSMASQ_CONFIG_HELP = 'dnsmasq config file (defaults to ' + DNSMASQ_CONFIG_FILE + ')'
BACKUP_HELP = 'backup output file before overwriting'
INSTALL_HELP_HELP = 'Help configure dnsmasq or /etc/hosts'
SOURCES_HELP = 'remote blacklist(s) to get rules from. Defaults to: ' + \
    ' '.join(DEFAULT_REMOTE_BLACKLISTS)
WHITELIST_HELP = '''\b
whitelists(s) defaults to:''' + CUSTOM_WHITELIST.replace(os.path.expanduser('~'), '~')
BLOCK_AT_PSL_HELP = 'strips subdomains, for example: analytics.google.com -> google.com' + \
    ' (must manually --whitelist inadvertently blocked domains)'
VERBOSE_HELP = 'print debug information to stderr'
NO_CACHE_HELP = 'do not cache --url files as sha1(url) to ~/.dnsgate/cache/'
CACHE_EXPIRE_HELP = 'seconds until a cached remote file is re-downloaded (defaults to 24 hours)'
DEST_IP_HELP = 'IP to redirect blocked connections to (defaults to ' + \
    '127.0.0.1 in hosts mode, specifying this in dnsmasq mode causes lookups to resolve rather than return NXDOMAIN)'
NO_RESTART_DNSMASQ_HELP = 'do not restart the dnsmasq service'
BLACKLIST_HELP = 'Add domain(s) to ' + CUSTOM_BLACKLIST
WHITELIST_HELP = 'Add domain(s) to ' + CUSTOM_WHITELIST
DISABLE_HELP = 'Disable ' + DEFAULT_OUTPUT_FILE
ENABLE_HELP = 'Enable ' + DEFAULT_OUTPUT_FILE
CONFIGURE_HELP = 'Write ' + CONFIG_FILE
GENERATE_HELP = 'Create ' + DEFAULT_OUTPUT_FILE

# https://github.com/mitsuhiko/click/issues/441
CONTEXT_SETTINGS = dict(help_option_names=['--help'], terminal_width=shutil.get_terminal_size((80, 20)).columns)

# pylint: disable=C0326
# http://pylint-messages.wikidot.com/messages:c0326
@click.group(context_settings=CONTEXT_SETTINGS)
@click.option('--no-restart-dnsmasq', is_flag=True,  help=NO_RESTART_DNSMASQ_HELP)
@click.option('--dnsmasq-config',  is_flag=False, help=DNSMASQ_CONFIG_HELP,
    type=click.File(mode='w', atomic=True), default=DNSMASQ_CONFIG_FILE)
@click.option('--backup',          is_flag=True,  help=BACKUP_HELP)
@click.option('--verbose',         is_flag=True,  help=VERBOSE_HELP, callback=set_verbose, expose_value=False)
# pylint: enable=C0326
@click.pass_context
def dnsgate(ctx, no_restart_dnsmasq, backup, dnsmasq_config):
    """dnsgate combines, deduplicates, and optionally modifies local and remote DNS blacklists. Use \"dnsgate (command) --help\" for more information."""

    if not os.path.isdir(CACHE_DIRECTORY):
        os.makedirs(CACHE_DIRECTORY)

    config = configparser.ConfigParser()
    if 'dnsgate configure' not in ' '.join(sys.argv):
        if 'dnsgate.py configure' not in ' '.join(sys.argv):
            try:
                with open(CONFIG_FILE, 'r') as cf:
                    config.read_file(cf)
            except FileNotFoundError:
                eprint("No configuration file found, run \"dnsgate configure --help\". Exiting.",
                    level=LOG_LEVELS['ERROR'])
                quit(1)

            mode = config['DEFAULT']['mode']
            block_at_psl = config['DEFAULT'].getboolean('block_at_psl')
            dest_ip = config['DEFAULT']['dest_ip']
            if dest_ip == 'False':
                dest_ip = None

            ctx.obj = Dnsgate_Config(mode=mode, block_at_psl=block_at_psl,
                dest_ip=dest_ip, no_restart_dnsmasq=no_restart_dnsmasq,
                backup=backup, dnsmasq_config=dnsmasq_config)

@dnsgate.command(help=WHITELIST_HELP)
@click.argument('domains', required=True, nargs=-1)
def whitelist(domains):
    for domain in domains:
        append_to_local_rule_file(CUSTOM_WHITELIST, domain)
    context = click.get_current_context()
    context.invoke(generate)

@dnsgate.command(help=BLACKLIST_HELP)
@click.argument('domains', required=True, nargs=-1)
def blacklist(domains):
    for domain in domains:
        append_to_local_rule_file(CUSTOM_BLACKLIST, domain)
    context = click.get_current_context()
    context.invoke(generate)

@dnsgate.command(help=INSTALL_HELP_HELP)
@click.pass_obj
def install_help(config):
    if config.mode == 'dnsmasq':
        dnsmasq_install_help(config.dnsmasq_config.name)
    elif config.mode == 'hosts':
        hosts_install_help()
    quit(0)

@dnsgate.command(help=ENABLE_HELP)
@click.pass_obj
def enable(config):
    if config.mode == 'dnsmasq':
        uncomment_line_in_file(dnsmasq_config, generate_dnsmasq_config_line(output.name))
        dnsmasq_config.close()
        restart_dnsmasq_service()
        if len(sys.argv) > 2:
            eprint("WARNING: exiting before any other modifications because --enable was used.",
                level=LOG_LEVELS['WARNING'])
        quit(0)
    else:
        eprint("ERROR: --enable is only available with --mode dnsmasq. Exiting.", level=LOG_LEVELS['ERROR'])
        quit(1)

@dnsgate.command(help=DISABLE_HELP)
@click.pass_obj
def disable(config):
    if config.mode == 'dnsmasq':
        comment_out_line_in_file(dnsmasq_config, generate_dnsmasq_config_line(output.name))
        dnsmasq_config.close()
        restart_dnsmasq_service()
        if len(sys.argv) > 2:
            eprint("WARNING: exiting before any other modifications because --disable was used.",
                level=LOG_LEVELS['WARNING'])
        quit(0)
    else:
        eprint("ERROR: --disable is only available with --mode dnsmasq. Exiting.", level=LOG_LEVELS['ERROR'])
        quit(1)

@dnsgate.command(help=CONFIGURE_HELP)
@click.option('--mode',            is_flag=False, type=click.Choice(['dnsmasq', 'hosts']), required=True)
@click.option('--block-at-psl',    is_flag=True,  help=BLOCK_AT_PSL_HELP)
@click.option('--dest-ip',         is_flag=False, help=DEST_IP_HELP, default=False)
def configure(mode, block_at_psl, dest_ip):
    config = configparser.ConfigParser()
    config['DEFAULT'] = \
        {
        'mode': mode,
        'block_at_psl': block_at_psl,
        'dest_ip': dest_ip
        }
    with open(CONFIG_FILE, 'w') as cf:
        config.write(cf)

@dnsgate.command(help=GENERATE_HELP)
@click.argument('sources',         nargs=-1)
@click.option('--no-cache',        is_flag=True,  help=NO_CACHE_HELP)
@click.option('--cache-expire',    is_flag=False, help=CACHE_EXPIRE_HELP, type=int, default=DEFAULT_CACHE_EXPIRE)
@click.option('--output',          is_flag=False, help=OUTPUT_FILE_HELP,
    type=click.File(mode='wb', atomic=True), default=DEFAULT_OUTPUT_FILE)
@click.pass_obj
def generate(config, sources, no_cache, cache_expire, output):

    if not sources:
        sources = DEFAULT_REMOTE_BLACKLISTS

    eprint('Using output file: %s', output.name, level=LOG_LEVELS['INFO'])
    config_dict = {
        'sources': sources,
        'block_at_psl': config.block_at_psl,
        'no_cache': no_cache,
        'cache_expire': cache_expire,
        'dest_ip': config.dest_ip,
        'output': output.name
        }

    domains_whitelist = set()
    eprint("Reading whitelist: %s", str(CUSTOM_WHITELIST), level=LOG_LEVELS['INFO'])
    whitelist_file = os.path.abspath(CUSTOM_WHITELIST)
    domains_whitelist = domains_whitelist | extract_domain_set_from_dnsgate_format_file(whitelist_file)
    if domains_whitelist:
        eprint("%d domains from the whitelist.", len(domains_whitelist), level=LOG_LEVELS['DEBUG'])
        domains_whitelist = validate_domain_list(domains_whitelist)
        eprint('%d validated whitelist domains.', len(domains_whitelist), level=LOG_LEVELS['INFO'])

    domains_combined_orig = set()   # domains from all sources, combined
    eprint("Reading remote blacklist(s):\n%s", str(sources), level=LOG_LEVELS['INFO'])
    for item in sources:
        if item.startswith('http'):
            try:
                eprint("Trying http:// blacklist location: %s", item, level=LOG_LEVELS['DEBUG'])
                domains = extract_domain_set_from_hosts_format_url_or_cached_copy(item, no_cache, cache_expire)
                if domains:
                    domains_combined_orig = domains_combined_orig | domains # union
                    eprint("len(domains_combined_orig): %s",
                        len(domains_combined_orig), level=LOG_LEVELS['DEBUG'])
                else:
                    print('ERROR: Failed to get ' + item + ', skipping.', level=LOG_LEVELS['ERROR'])
                    continue
            except Exception as e:
                logger_quiet.logger.error("Exception on blacklist url: %s", item)
                logger_quiet.logger.exception(e)
        else:
            eprint('ERROR: ' + item + ' must start with http:// or https://, skipping.', level=LOG_LEVELS['ERROR'])

    eprint("%d domains from remote blacklist(s).", len(domains_combined_orig), level=LOG_LEVELS['INFO'])

    if len(domains_combined_orig) == 0:
        eprint("WARNING: 0 domains were retrieved from " +
            "remote sources, only the local " + CUSTOM_BLACKLIST +
            " will be used.", level=LOG_LEVELS['WARNING'])

    domains_combined_orig = validate_domain_list(domains_combined_orig)
    eprint('%d validated remote blacklisted domains.',
        len(domains_combined_orig), level=LOG_LEVELS['INFO'])

    domains_combined = copy.deepcopy(domains_combined_orig) # need to iterate through _orig later

    if config.block_at_psl and config.mode != 'hosts':
        domains_combined = strip_to_psl(domains_combined)
        eprint("%d blacklisted domains left after stripping to PSL domains.",
            len(domains_combined), level=LOG_LEVELS['INFO'])

        eprint("Subtracting %d whitelisted domains.",
            len(domains_whitelist), level=LOG_LEVELS['INFO'])
        domains_combined = domains_combined - domains_whitelist
        eprint("%d blacklisted domains left after subtracting the whitelist.",
            len(domains_combined), level=LOG_LEVELS['INFO'])

        eprint('Iterating through the original %d whitelisted domains and ' +
            'making sure none are blocked by * rules.',
            len(domains_whitelist), level=LOG_LEVELS['INFO'])

        for domain in domains_whitelist:
            domain_psl = extract_psl_domain(domain)
            if domain_psl in domains_combined:
                domains_combined.remove(domain_psl)

        eprint('Iterating through original %d blacklisted domains to re-add subdomains' +
            ' that are not whitelisted', len(domains_combined_orig), level=LOG_LEVELS['INFO'])
        # re-add subdomains that are not explicitly whitelisted or already blocked
        for orig_domain in domains_combined_orig: # check every original full hostname
            if orig_domain not in domains_whitelist: # if it's not in the whitelist
                if orig_domain not in domains_combined: # and it's not in the current blacklist
                                                        # (almost none will be if --block-at-psl)
                    orig_domain_psl = extract_psl_domain(orig_domain)   # get it's psl to see if it's already blocked

                    if orig_domain_psl not in domains_combined: # if the psl is not already blocked
                        eprint("Re-adding: %s", orig_domain, level=LOG_LEVELS['DEBUG'])
                        domains_combined.add(orig_domain) # add the full hostname to the blacklist

        eprint('%d blacklisted domains after re-adding non-explicitly blacklisted subdomains',
            len(domains_combined), level=LOG_LEVELS['INFO'])

    elif config.block_at_psl and config.mode == 'hosts':
        logger_quiet.logger.error("ERROR: --block-at-psl is not possible in hosts mode. Exiting.")
        quit(1)

    # apply whitelist before applying local blacklist
    domains_combined = domains_combined - domains_whitelist  # remove exact whitelist matches
    eprint("%d blacklisted domains after subtracting the %d whitelisted domains",
        len(domains_combined), len(domains_whitelist), level=LOG_LEVELS['INFO'])

    # must happen after subdomain stripping and after whitelist subtraction
    blacklist_file = os.path.abspath(CUSTOM_BLACKLIST)
    domains = extract_domain_set_from_dnsgate_format_file(blacklist_file)
    if domains:
        eprint("Got %s domains from the CUSTOM_BLACKLIST: %s",
            domains, blacklist_file, level=LOG_LEVELS['DEBUG'])
        eprint("Re-adding %d domains in the local blacklist %s to override the whitelist.",
            len(domains), CUSTOM_BLACKLIST, level=LOG_LEVELS['INFO'])
        domains_combined = domains_combined | domains # union
    eprint("%d blacklisted domains after re-adding the custom blacklist.",
        len(domains_combined), level=LOG_LEVELS['INFO'])

    eprint("Validating final domain block list.", level=LOG_LEVELS['DEBUG'])
    domains_combined = validate_domain_list(domains_combined)
    eprint('%d validated blacklisted domains.', len(domains_combined),
        level=LOG_LEVELS['DEBUG'])

    domains_combined = prune_redundant_rules(domains_combined)
    eprint('%d balcklisted domains after removing redundant rules.', len(domains_combined),
        level=LOG_LEVELS['INFO'])

    domains_combined = group_by_tld(domains_combined) # do last, returns sorted list
    eprint('Final blacklisted domain count: %d', len(domains_combined),
        level=LOG_LEVELS['INFO'])

    if config.backup: # todo: unit test
        backup_file_if_exists(output)

    try:
        os.mkdir(CONFIG_DIRECTORY)
    except FileExistsError:
        pass

    if not domains_combined:
        logger_quiet.logger.error("The list of domains to block is empty, nothing to do, exiting.")
        quit(1)

    for domain in domains_whitelist:
        domain_tld = extract_psl_domain(domain)
        if domain_tld in domains_combined:
            eprint('WARNING: %s is listed in both %s and %s, the local blacklist always takes precedence.',
                domain.decode('UTF8'), CUSTOM_BLACKLIST, CUSTOM_WHITELIST, level=LOG_LEVELS['WARNING'])

    eprint("Writing output file: %s in %s format", output.name, config.mode, level=LOG_LEVELS['INFO'])

    output.write(make_output_file_header(config_dict))

    for domain in domains_combined:
        if config.mode == 'dnsmasq':
            if config.dest_ip:
                dnsmasq_line = 'address=/.' + domain.decode('utf8') + '/' + config.dest_ip + '\n'
            else:
                dnsmasq_line = 'server=/.' + domain.decode('utf8') + '/' '\n'  # return NXDOMAIN
            output.write(dnsmasq_line.encode('utf8'))
        elif config.mode == 'hosts':
            if config.dest_ip:
                hosts_line = config.dest_ip + ' ' + domain.decode('utf8') + '\n'
            else:
                hosts_line = '127.0.0.1' + ' ' + domain.decode('utf8') + '\n'
            output.write(hosts_line.encode('utf8'))

    output.close() # make sure file is written before restarting dnsmasq

    if not config.no_restart_dnsmasq:
        if config.mode != 'hosts':
            restart_dnsmasq_service()


if __name__ == '__main__':
    # pylint: disable=no-value-for-parameter
    dnsgate()
    # pylint: enable=no-value-for-parameter
    eprint("Exiting without error.", level=LOG_LEVELS['DEBUG'])
    quit(0)
